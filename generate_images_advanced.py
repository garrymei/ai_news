#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«˜çº§AIæ–°é—»å›¾ç‰‡ç”Ÿæˆå™¨
æ”¯æŒå¤šç§å›¾ç‰‡ç”Ÿæˆæ–¹æ¡ˆï¼šMCPã€åœ¨çº¿APIã€æœ¬åœ°ç”Ÿæˆ
"""
import os, json, glob, datetime, hashlib, time
from PIL import Image, ImageDraw, ImageFont, ImageFilter, ImageEnhance
import random, requests
from dateutil.tz import tzlocal
import subprocess
import base64
from io import BytesIO

# é…ç½®
W, H = 1080, 1920  # ç«–å±å°ºå¯¸
FONT_PATH = "/System/Library/Fonts/Hiragino Sans GB.ttc"

def latest(path):
    files = sorted(glob.glob(path), reverse=True)
    return files[0] if files else ""

def get_today_str():
    tz = tzlocal()
    now = datetime.datetime.now(tz)
    return now.astimezone().strftime("%Y-%m-%d")

def translate_to_english_prompt(chinese_text):
    """å°†ä¸­æ–‡æ–°é—»è½¬æ¢ä¸ºè‹±æ–‡å›¾ç‰‡ç”Ÿæˆæç¤ºè¯"""
    # ç®€å•çš„å…³é”®è¯æ˜ å°„
    keyword_map = {
        "OpenAI": "OpenAI artificial intelligence",
        "GPT": "GPT language model technology",
        "Anthropic": "Anthropic AI company",
        "Claude": "Claude AI assistant",
        "æœºå™¨äºº": "advanced robotics technology",
        "äººå·¥æ™ºèƒ½": "artificial intelligence AI",
        "MIT": "MIT university research laboratory",
        "å¯¼èˆª": "navigation autonomous system",
        "ç®—æ³•": "algorithm computer science",
        "æ·±åº¦å­¦ä¹ ": "deep learning neural network",
        "æ•°æ®": "data analytics technology",
        "ç§‘æŠ€": "technology innovation",
        "ç ”å‘": "research development laboratory",
        "çªç ´": "breakthrough innovation",
        "å‘å¸ƒ": "product launch announcement"
    }
    
    # æ„å»ºè‹±æ–‡æç¤ºè¯
    prompt_parts = []
    for chinese, english in keyword_map.items():
        if chinese in chinese_text:
            prompt_parts.append(english)
    
    if not prompt_parts:
        prompt_parts = ["artificial intelligence", "technology innovation"]
    
    # æ·»åŠ é€šç”¨é£æ ¼æè¿°
    style_keywords = [
        "professional", "modern", "high-tech", "blue color scheme",
        "digital graphics", "clean design", "corporate style",
        "technology background", "futuristic", "sleek interface"
    ]
    
    prompt = ", ".join(prompt_parts[:3] + style_keywords[:4])
    return prompt

def generate_with_stability_api(prompt, output_path):
    """ä½¿ç”¨Stability AI APIç”Ÿæˆå›¾ç‰‡ (éœ€è¦API key)"""
    try:
        api_key = os.getenv("STABILITY_API_KEY")
        if not api_key:
            return False
            
        url = "https://api.stability.ai/v1/generation/stable-diffusion-xl-1024-v1-0/text-to-image"
        
        headers = {
            "Accept": "application/json",
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        data = {
            "text_prompts": [
                {
                    "text": prompt,
                    "weight": 1
                }
            ],
            "cfg_scale": 7,
            "height": 1920,
            "width": 1080,
            "samples": 1,
            "steps": 30,
        }
        
        response = requests.post(url, headers=headers, json=data, timeout=60)
        
        if response.status_code == 200:
            data = response.json()
            if data["artifacts"]:
                image_data = base64.b64decode(data["artifacts"][0]["base64"])
                with open(output_path, "wb") as f:
                    f.write(image_data)
                return True
        
        return False
        
    except Exception as e:
        print(f"  âŒ Stability APIé”™è¯¯: {e}")
        return False

def generate_with_local_diffusion(prompt, output_path):
    """ä½¿ç”¨æœ¬åœ°Stable Diffusionç”Ÿæˆå›¾ç‰‡ (å¦‚æœå·²å®‰è£…)"""
    try:
        # æ£€æŸ¥æ˜¯å¦å®‰è£…äº†diffusers
        import torch
        from diffusers import StableDiffusionPipeline
        
        # åŠ è½½æ¨¡å‹ (é¦–æ¬¡è¿è¡Œä¼šä¸‹è½½ï¼Œéœ€è¦æ—¶é—´)
        pipe = StableDiffusionPipeline.from_pretrained(
            "runwayml/stable-diffusion-v1-5",
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
        )
        
        if torch.cuda.is_available():
            pipe = pipe.to("cuda")
        
        # ç”Ÿæˆå›¾ç‰‡
        image = pipe(
            prompt,
            height=1920,
            width=1080,
            num_inference_steps=20,
            guidance_scale=7.5
        ).images[0]
        
        image.save(output_path)
        return True
        
    except ImportError:
        print("  âš ï¸ æœªå®‰è£…diffusersåº“ï¼Œè·³è¿‡æœ¬åœ°Stable Diffusion")
        return False
    except Exception as e:
        print(f"  âŒ æœ¬åœ°Diffusioné”™è¯¯: {e}")
        return False

def create_enhanced_local_image(title, summary, source, output_path):
    """å¢å¼ºç‰ˆæœ¬åœ°å›¾ç‰‡ç”Ÿæˆ"""
    # è·å–ä¸»é¢˜è‰²å½©
    content = (title + " " + summary).lower()
    
    # æ›´ä¸°å¯Œçš„ä¸»é¢˜è‰²å½©æ–¹æ¡ˆ
    if "openai" in content or "gpt" in content:
        colors = [(74, 222, 128), (34, 197, 94)]  # ç»¿è‰² (OpenAIä¸»é¢˜è‰²)
    elif "anthropic" in content or "claude" in content:
        colors = [(251, 146, 60), (249, 115, 22)]  # æ©™è‰² (Anthropicä¸»é¢˜è‰²)
    elif "æœºå™¨äºº" in content or "robot" in content:
        colors = [(168, 85, 247), (139, 69, 219)]  # ç´«è‰²
    elif "mit" in content or "ç ”ç©¶" in content:
        colors = [(59, 130, 246), (37, 99, 235)]  # è“è‰²
    else:
        colors = [(14, 165, 233), (2, 132, 199)]  # é»˜è®¤è“è‰²
    
    # åˆ›å»ºæ¸å˜èƒŒæ™¯
    img = Image.new('RGB', (W, H), colors[0])
    
    # åˆ›å»ºå¤æ‚æ¸å˜
    for y in range(H):
        for x in range(W):
            # å¾„å‘æ¸å˜æ•ˆæœ
            center_x, center_y = W//3, H//4
            distance = ((x - center_x)**2 + (y - center_y)**2)**0.5
            max_distance = (W**2 + H**2)**0.5
            ratio = min(distance / max_distance * 2, 1.0)
            
            r = int(colors[0][0] * (1 - ratio) + colors[1][0] * ratio)
            g = int(colors[0][1] * (1 - ratio) + colors[1][1] * ratio)
            b = int(colors[0][2] * (1 - ratio) + colors[1][2] * ratio)
            
            img.putpixel((x, y), (r, g, b))
    
    # æ·»åŠ ç§‘æŠ€æ„Ÿå›¾æ¡ˆ
    draw = ImageDraw.Draw(img)
    
    # æ·»åŠ å‡ ä½•å›¾å½¢
    for i in range(8):
        x = random.randint(0, W)
        y = random.randint(0, H//2)
        size = random.randint(30, 120)
        alpha = random.randint(10, 40)
        
        # åˆ›å»ºåŠé€æ˜å›¾å±‚
        overlay = Image.new('RGBA', (W, H), (255, 255, 255, 0))
        overlay_draw = ImageDraw.Draw(overlay)
        
        # éšæœºå‡ ä½•å½¢çŠ¶
        shape_type = random.choice(['circle', 'rectangle', 'triangle'])
        if shape_type == 'circle':
            overlay_draw.ellipse([x, y, x+size, y+size], fill=(255, 255, 255, alpha))
        elif shape_type == 'rectangle':
            overlay_draw.rectangle([x, y, x+size, y+size//2], fill=(255, 255, 255, alpha))
        
        img = Image.alpha_composite(img.convert('RGBA'), overlay).convert('RGB')
    
    # æ·»åŠ ç½‘æ ¼çº¿æ¡
    draw = ImageDraw.Draw(img)
    grid_color = (255, 255, 255, 30)
    
    # å‚ç›´çº¿
    for x in range(0, W, 80):
        draw.line([(x, 0), (x, H//2)], fill=grid_color, width=1)
    
    # æ°´å¹³çº¿  
    for y in range(0, H//2, 80):
        draw.line([(0, y), (W, y)], fill=grid_color, width=1)
    
    # è½¬æ¢ä¸ºRGBAæ·»åŠ æ–‡å­—å±‚
    img = img.convert('RGBA')
    
    # æ·»åŠ æ–‡å­—èƒŒæ™¯
    overlay = Image.new('RGBA', (W, H), (0, 0, 0, 0))
    draw = ImageDraw.Draw(overlay)
    
    # é¡¶éƒ¨å“ç‰ŒåŒºåŸŸ
    draw.rectangle([(0, 0), (W, 180)], fill=(0, 0, 0, 100))
    
    # åº•éƒ¨æ–‡å­—åŒºåŸŸ
    draw.rectangle([(0, H*2//3), (W, H)], fill=(0, 0, 0, 140))
    
    img = Image.alpha_composite(img, overlay)
    
    # æ·»åŠ æ–‡å­—
    draw = ImageDraw.Draw(img)
    
    # åŠ è½½å­—ä½“
    try:
        font_large = ImageFont.truetype(FONT_PATH, 64)
        font_medium = ImageFont.truetype(FONT_PATH, 42)
        font_small = ImageFont.truetype(FONT_PATH, 32)
    except:
        font_large = ImageFont.load_default()
        font_medium = ImageFont.load_default()
        font_small = ImageFont.load_default()
    
    # å“ç‰Œæ ‡è¯†
    draw.text((60, 60), "AIç§‘æŠ€èµ„è®¯", font=font_medium, fill=(255, 255, 255), stroke_width=2, stroke_fill=(0,0,0))
    draw.text((60, 120), f"ğŸ“° {source}", font=font_small, fill=(200, 200, 200))
    
    # ä¸»æ ‡é¢˜å¤„ç†
    y_pos = H*2//3 + 60
    title_lines = []
    
    # æ™ºèƒ½æ¢è¡Œ
    if len(title) > 16:
        # å¯»æ‰¾åˆé€‚çš„æ–­ç‚¹
        break_chars = "ï¼Œã€‚ï¼ï¼Ÿã€"
        best_break = len(title) // 2
        
        for i in range(len(title)//2 - 5, len(title)//2 + 5):
            if i < len(title) and title[i] in break_chars:
                best_break = i + 1
                break
        
        title_lines = [title[:best_break].strip(), title[best_break:].strip()]
    else:
        title_lines = [title]
    
    # ç»˜åˆ¶æ ‡é¢˜
    for i, line in enumerate(title_lines):
        if line:
            draw.text((60, y_pos + i * 85), line, font=font_large, fill=(255, 255, 255), 
                     stroke_width=1, stroke_fill=(0,0,0))
    
    # æ‘˜è¦
    y_pos += len(title_lines) * 85 + 30
    summary_text = summary[:80] + "..." if len(summary) > 80 else summary
    draw.text((60, y_pos), summary_text, font=font_medium, fill=(220, 220, 220))
    
    # æ·»åŠ è£…é¥°å…ƒç´ 
    draw.ellipse([(W-150, 50), (W-50, 150)], outline=(255, 255, 255, 100), width=3)
    draw.text((W-120, 90), "AI", font=font_medium, fill=(255, 255, 255, 150))
    
    # ä¿å­˜
    final_img = img.convert('RGB')
    final_img.save(output_path, quality=95, optimize=True)
    return True

def generate_news_image_advanced(title, summary, source, output_path):
    """é«˜çº§å›¾ç‰‡ç”Ÿæˆï¼Œå°è¯•å¤šç§æ–¹æ¡ˆ"""
    print(f"  ğŸ¨ ç”Ÿæˆå›¾ç‰‡: {title[:30]}...")
    
    # æ–¹æ¡ˆ1: å°è¯•åœ¨çº¿API (å¦‚æœé…ç½®äº†)
    english_prompt = translate_to_english_prompt(title + " " + summary)
    print(f"  ğŸ“ è‹±æ–‡æç¤ºè¯: {english_prompt}")
    
    if generate_with_stability_api(english_prompt, output_path):
        print(f"  âœ… Stability AIç”ŸæˆæˆåŠŸ")
        return True
    
    # æ–¹æ¡ˆ2: å°è¯•æœ¬åœ°Stable Diffusion
    if generate_with_local_diffusion(english_prompt, output_path):
        print(f"  âœ… æœ¬åœ°Diffusionç”ŸæˆæˆåŠŸ")
        return True
    
    # æ–¹æ¡ˆ3: å¢å¼ºç‰ˆæœ¬åœ°å›¾ç‰‡ç”Ÿæˆ
    if create_enhanced_local_image(title, summary, source, output_path):
        print(f"  âœ… å¢å¼ºæœ¬åœ°ç”ŸæˆæˆåŠŸ")
        return True
    
    print(f"  âŒ æ‰€æœ‰å›¾ç‰‡ç”Ÿæˆæ–¹æ¡ˆå¤±è´¥")
    return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨é«˜çº§AIæ–°é—»å›¾ç‰‡ç”Ÿæˆå™¨...")
    
    # è·å–æ–°é—»æ•°æ®
    news_json = latest("output/news/*.json")
    if not news_json:
        print("âŒ æœªæ‰¾åˆ°æ–°é—»æ•°æ®")
        return
    
    with open(news_json, "r", encoding="utf-8") as f:
        items = json.load(f)
    
    if not items:
        print("âŒ æ–°é—»æ•°æ®ä¸ºç©º")
        return
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs("assets/ai_generated_images", exist_ok=True)
    
    print(f"ğŸ“° å¤„ç† {len(items)} æ¡æ–°é—»...")
    
    # ç”Ÿæˆå›¾ç‰‡
    success_count = 0
    for i, item in enumerate(items):
        title = item.get("title", "")
        summary = item.get("summary", "")
        source = item.get("source", "")
        
        if not title:
            continue
        
        # ç”Ÿæˆæ–‡ä»¶å
        filename = f"ai_news_{i+1}_{hashlib.md5(title.encode()).hexdigest()[:8]}.jpg"
        output_path = f"assets/ai_generated_images/{filename}"
        
        if generate_news_image_advanced(title, summary, source, output_path):
            item["image_path"] = output_path
            success_count += 1
        else:
            # å¤‡ç”¨ï¼šä½¿ç”¨å ä½å›¾ç‰‡
            item["image_path"] = "assets/placeholder.jpg"
        
        time.sleep(1)  # é¿å…APIé™åˆ¶
    
    # ä¿å­˜æ›´æ–°çš„æ–°é—»æ•°æ®
    with open(news_json, "w", encoding="utf-8") as f:
        json.dump(items, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… å®Œæˆï¼æˆåŠŸç”Ÿæˆ {success_count}/{len(items)} å¼ å›¾ç‰‡")
    print(f"ğŸ“ å›¾ç‰‡ä¿å­˜åœ¨: assets/ai_generated_images/")

if __name__ == "__main__":
    main()
